️ None-Scailing(Include ['remaining_contract'])

| 모델                     | Accuracy | F1 Score |
| ---------------------- | -------- | -------- |
| **XGBClassifier**      | 0.9410   | 0.9464   |
| **CatBoostClassifier** | 0.9410   | 0.9464   |
| SVC                    | 0.8531   | 0.8689   |
| RandomForestClassifier | 0.9396   | 0.9450   |
| LogisticRegression     | 0.8716   | 0.8876   |

상위 두 모델의 점수가 90점을 초과하여 과적합 우려가 있어 ['remaining_contract'] 컬럼을 제거하고 학습한다.

📋 XGBClassifier (Exclude ['remaining_contract'])

| Scaler         | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| None           | **0.8424** | **0.8887** | 0.8265     | **0.8565** | **0.8450** |
| Standard       | **0.8424** | **0.8887** | 0.8265     | **0.8565** | **0.8450** |
| MinMax         | **0.8424** | **0.8887** | 0.8265     | **0.8565** | **0.8450** |
| Robust         | **0.8424** | **0.8887** | 0.8265     | **0.8565** | **0.8450** |
| MaxAbs         | **0.8424** | **0.8887** | 0.8265     | **0.8565** | **0.8450** |
| QuantileTransf | **0.8429** | 0.8865     | **0.8300** | **0.8573** | 0.8449     |

🐈 CatBoostClassifier

| Scaler         | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| None           | **0.8437** | 0.8868     | 0.8313     | **0.8582** | **0.8457** |
| Standard       | **0.8437** | 0.8868     | 0.8313     | **0.8582** | **0.8457** |
| MinMax         | **0.8437** | 0.8868     | 0.8313     | **0.8582** | **0.8457** |
| Robust         | **0.8437** | 0.8868     | 0.8313     | **0.8582** | **0.8457** |
| MaxAbs         | **0.8437** | 0.8868     | 0.8313     | **0.8582** | **0.8457** |
| QuantileTransf | 0.8424     | **0.8857** | **0.8300** | 0.8569     | 0.8444     |

🔍 SVC

| Scaler         | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| None           | 0.7595     | 0.8183     | 0.7418     | 0.7782     | 0.7623     |
| Standard       | **0.7839** | **0.8498** | 0.7532     | **0.7986** | **0.7888** |
| MinMax         | 0.7229     | 0.7584     | 0.7527     | 0.7555     | 0.7182     |
| Robust         | 0.7815     | 0.8452     | **0.7539** | 0.7970     | 0.7859     |
| MaxAbs         | 0.7229     | 0.7584     | 0.7527     | 0.7555     | 0.7182     |
| QuantileTransf | 0.7844     | 0.8615     | 0.7400     | 0.7961     | 0.7915     |

🌳 RandomForestClassifier

| Scaler         | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| None           | 0.8291     | 0.8783     | 0.8120     | 0.8439     | 0.8318     |
| Standard       | 0.8291     | 0.8777     | 0.8127     | 0.8440     | 0.8317     |
| MinMax         | 0.8292     | 0.8784     | 0.8122     | 0.8440     | 0.8319     |
| Robust         | **0.8295** | **0.8785** | **0.8125** | **0.8442** | **0.8322** |
| MaxAbs         | 0.8292     | 0.8784     | 0.8122     | 0.8440     | 0.8319     |
| QuantileTransf | 0.8292     | 0.8784     | 0.8122     | 0.8440     | 0.8319     |

➕ LogisticRegression

| Scaler         | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| None           | **0.7334** | **0.7466** | **0.8041** | **0.7743** | **0.7221** |
| Standard       | **0.7334** | **0.7466** | **0.8041** | **0.7743** | **0.7221** |
| MinMax         | 0.7025     | 0.7144     | 0.7946     | 0.7524     | 0.6878     |
| Robust         | **0.7335** | **0.7467** | **0.8044** | **0.7744** | **0.7222** |
| MaxAbs         | 0.7025     | 0.7144     | 0.7946     | 0.7524     | 0.6878     |
| QuantileTransf | 0.7025     | 0.7144     | 0.7946     | 0.7524     | 0.6878     |

✔️ 최적의 머신러닝 학습 모델과 스케일러
- XGBClassifier 모델 중 Quantiltransformer scaler를 사용한 모델이 1등.
- XGBClassifier는 1등 값을 제외하고 나머지 값도 다른 모델들 보다 우수.
- 2등은 CatBoost 모델로 XGBClassifier와 큰 차이가 나지 않음.
- 모델의 다양성을 위해 XGBClassifier와 CatBoost 모델을 하이퍼 파라미터를 수정해가며 동시에 학습, 결과 값을 확인 할 예정이다.

